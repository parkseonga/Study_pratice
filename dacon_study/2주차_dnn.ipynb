{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베이스라인 모델 발전시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. node 수 조절\n",
    "    - 세 개의 hidden layer의 unit 수를 각각 input_dim의 2배, 1배, 1/2배로 설정   \n",
    "     \n",
    "     \n",
    "2. hidden layer 추가\n",
    "    - hidden layer를 추가하여 총 4개의 hidden layer 생성\n",
    "    - 각 layer의 unit 수를 2배, 3/2배, 1배, 1/2배로 설정\n",
    "    \n",
    "    \n",
    "3. batch size 조절\n",
    "    - batch size가 큰 경우: 기울기를 계산하기 위해 더 많은 데이터를 사용하게 됨. 최적화시켜야하는 전체 데이터를 사용한 해공간의 기울기 값고 유사한 기울기를 사용하므로 최적화가 더 수월해질 수 있지만 실제 최적화 시켜야할 문제 공간이 평평한 경우에는 실제와 유사하게 근사된 기울기의 절대값이 작아 수렴 속도가 매우 느려질 수 있음. 극단적인 경우에는 local minima or saddle point에 빠져서 loss가 줄어들지 않을 수도 있음.    \n",
    "    \n",
    "    - batch size가 작은 경우 상대적으로 부정확한 기울기를 사용한다는 단점이 있지만 한 번의 업데이터에 적은 계산 비용이 들어가 한 번 업데이트 할 동안 여러번의 업데이트를 수행할 수 있고 기울기의 부정확한 면이 랜덤성으로 작용해 실제 기울기가 낮은 구간이나 local minima or saddle point에서 쉽게 벗어날 가능성이 있음.\n",
    "     \n",
    "     \n",
    "4. epoch 조절\n",
    "    - 학습하는 양을 늘리며 overfitting이 되지않도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 불러옵니다.\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # warning message 안나오도록함.\n",
    "\n",
    "#케라스를 통해 모델 생성을 시작합니다.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#독립변수와 종속변수를 분리합니다.\n",
    "train_X = train.iloc[:,4:]\n",
    "train_Y = train.iloc[:,0:4]\n",
    "test_X = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # model 초기화 \n",
    "model.add(Dense(units=452, activation='relu', input_dim=226))  # 첫번째 은닉층  # 226개 feature, 160개 뉴런, relu 함수를 활성화 함수로 사용\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=226, activation='relu'))   # 두번째 은닉층  \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=113, activation='relu'))   # 세번째 은닉층\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=4, activation='linear'))   # 출력층 (4개의 output을 도출해내야되기 때문에 units = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 109.8925 - mae: 109.8925 - val_loss: 72.2479 - val_mae: 72.2479\n",
      "Epoch 2/30\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 44.7987 - mae: 44.7987 - val_loss: 54.2952 - val_mae: 54.2952\n",
      "Epoch 3/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 31.6174 - mae: 31.6174 - val_loss: 44.3628 - val_mae: 44.3628\n",
      "Epoch 4/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 26.7964 - mae: 26.7964 - val_loss: 43.9438 - val_mae: 43.9438\n",
      "Epoch 5/30\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 24.1662 - mae: 24.1662 - val_loss: 42.7789 - val_mae: 42.7789\n",
      "Epoch 6/30\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 22.5039 - mae: 22.5040 - val_loss: 39.8026 - val_mae: 39.8026\n",
      "Epoch 7/30\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 21.3276 - mae: 21.3276 - val_loss: 41.8746 - val_mae: 41.8746\n",
      "Epoch 8/30\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 20.4452 - mae: 20.4452 - val_loss: 37.7250 - val_mae: 37.7250\n",
      "Epoch 9/30\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 19.7170 - mae: 19.7170 - val_loss: 38.7058 - val_mae: 38.7058\n",
      "Epoch 10/30\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 19.0991 - mae: 19.0991 - val_loss: 39.5338 - val_mae: 39.5338\n",
      "Epoch 11/30\n",
      "769500/769500 [==============================] - 30s 38us/step - loss: 18.6082 - mae: 18.6082 - val_loss: 36.8771 - val_mae: 36.8771\n",
      "Epoch 12/30\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 18.1287 - mae: 18.1287 - val_loss: 36.6777 - val_mae: 36.6777\n",
      "Epoch 13/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 17.7458 - mae: 17.7458 - val_loss: 36.8805 - val_mae: 36.8805\n",
      "Epoch 14/30\n",
      "769500/769500 [==============================] - 30s 38us/step - loss: 17.4159 - mae: 17.4159 - val_loss: 36.2361 - val_mae: 36.2361\n",
      "Epoch 15/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 17.1033 - mae: 17.1033 - val_loss: 35.6423 - val_mae: 35.6423\n",
      "Epoch 16/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 16.7886 - mae: 16.7886 - val_loss: 35.0590 - val_mae: 35.0590\n",
      "Epoch 17/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 16.5257 - mae: 16.5257 - val_loss: 34.9332 - val_mae: 34.9332\n",
      "Epoch 18/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 16.2841 - mae: 16.2841 - val_loss: 33.6074 - val_mae: 33.6074\n",
      "Epoch 19/30\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 16.0431 - mae: 16.0431 - val_loss: 34.9153 - val_mae: 34.9153\n",
      "Epoch 20/30\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 15.8221 - mae: 15.8221 - val_loss: 34.0805 - val_mae: 34.0805\n",
      "Epoch 21/30\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 15.5986 - mae: 15.5986 - val_loss: 34.4532 - val_mae: 34.4532\n",
      "Epoch 22/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 15.4429 - mae: 15.4429 - val_loss: 34.1847 - val_mae: 34.1847\n",
      "Epoch 23/30\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 15.2686 - mae: 15.2685 - val_loss: 33.6608 - val_mae: 33.6608\n",
      "Epoch 24/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 15.0657 - mae: 15.0657 - val_loss: 33.6293 - val_mae: 33.6293\n",
      "Epoch 25/30\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 14.9377 - mae: 14.9377 - val_loss: 32.6171 - val_mae: 32.6171\n",
      "Epoch 26/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 14.7812 - mae: 14.7812 - val_loss: 33.0838 - val_mae: 33.0838\n",
      "Epoch 27/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 14.6460 - mae: 14.6460 - val_loss: 32.9539 - val_mae: 32.9539\n",
      "Epoch 28/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 14.5450 - mae: 14.5450 - val_loss: 32.3318 - val_mae: 32.3318\n",
      "Epoch 29/30\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 14.3702 - mae: 14.3702 - val_loss: 31.9032 - val_mae: 31.9032\n",
      "Epoch 30/30\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 14.3036 - mae: 14.3036 - val_loss: 31.9144 - val_mae: 31.9144\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y, epochs=30, batch_size=1000, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d20604e548>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission 파일을 생성합니다.\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission = sample_sub+pred_test\n",
    "submission.to_csv('submission2_30_batch_add.csv') # 14.437 그냥 scaler 한 것의 성능이 더 좋음. \n",
    "# submission.to_csv('submission2_30.csv')   # 24.890   # epoch 500으로 늘리면 12.870"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* epoch를 500으로 늘리고 unit 수를 feature 개수의 배수로 지정했을 때 24.890 점수가 나옴.    \n",
    "\n",
    "\n",
    "* 배치정규화(BatchNormalization)를 이용하여 gradient vanishing 현상이 일어나지 않고 안정적으로 학습될 수 있도록함. \n",
    "\n",
    "    - 배치정규화: input의 분포가 달라져 Internal Covariance Shift 현상으로 인해 gradient vanishing가 발생하는 것을 막기 위해 input값을 평균 0, 분산1로 정규화하여 네트워크의 학습이 안정적으로 일어나도록 함. \n",
    "        - batch_size 값에 따라 가중치를 업데이터하는 것으로 각 batch_size 개수만큼의 데이터 인스턴스가 feature별로 정규화됨. \n",
    "        - 장점\n",
    "            - 초기 learning rate를 크게 설정해도 안정적으로 수렴할 수 있음.\n",
    "            - activation 값을 적당한 크기로 유지하기 때문에 gradient vanishing 현상을 어느정도 막을 수 있음.\n",
    "            - input의 분포들이 안정화되면서 손실함수가 더 빠르고 더 좋은 값으로 수렴할 수 있음.\n",
    "            \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표준 정규화 적용 후 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fit은 train에만 \n",
    "train_x = scaler.fit_transform(train_X)\n",
    "test_x = scaler.transform(test_X)\n",
    "\n",
    "train_y = scaler.fit_transform(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  # model 초기화 \n",
    "model.add(Dense(units=452, activation='relu', input_dim=226))  # 첫번째 은닉층  # 226개 feature, 160개 뉴런, relu 함수를 활성화 함수로 사용\n",
    "model.add(Dense(units=226, activation='relu'))   # 두번째 은닉층  \n",
    "model.add(Dense(units=113, activation='relu'))   # 세번째 은닉층\n",
    "model.add(Dense(units=4, activation='linear'))   # 출력층 (4개의 output을 도출해내야되기 때문에 units = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/30\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.2244 - mae: 0.2244 - val_loss: 0.3980 - val_mae: 0.3980\n",
      "Epoch 2/30\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.2072 - mae: 0.2072 - val_loss: 0.3634 - val_mae: 0.3634\n",
      "Epoch 3/30\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.1945 - mae: 0.1945 - val_loss: 0.3710 - val_mae: 0.3710\n",
      "Epoch 4/30\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.1843 - mae: 0.1843 - val_loss: 0.3583 - val_mae: 0.3583s - loss: 0.1845 -\n",
      "Epoch 5/30\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.1761 - mae: 0.1761 - val_loss: 0.3485 - val_mae: 0.3485\n",
      "Epoch 6/30\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.3528 - val_mae: 0.3528\n",
      "Epoch 7/30\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.1628 - mae: 0.1628 - val_loss: 0.3515 - val_mae: 0.3515\n",
      "Epoch 8/30\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.1578 - mae: 0.1578 - val_loss: 0.3515 - val_mae: 0.3515\n",
      "Epoch 9/30\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.1530 - mae: 0.1530 - val_loss: 0.3443 - val_mae: 0.3443\n",
      "Epoch 10/30\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.1489 - mae: 0.1489 - val_loss: 0.3403 - val_mae: 0.3403\n",
      "Epoch 11/30\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.1453 - mae: 0.1453 - val_loss: 0.3422 - val_mae: 0.3422\n",
      "Epoch 12/30\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.1415 - mae: 0.1415 - val_loss: 0.3252 - val_mae: 0.3252\n",
      "Epoch 13/30\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.1387 - mae: 0.1387 - val_loss: 0.3277 - val_mae: 0.3277\n",
      "Epoch 14/30\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.1358 - mae: 0.1358 - val_loss: 0.3265 - val_mae: 0.3265\n",
      "Epoch 15/30\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.3200 - val_mae: 0.3200\n",
      "Epoch 16/30\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.1309 - mae: 0.1309 - val_loss: 0.3136 - val_mae: 0.3136\n",
      "Epoch 17/30\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.1284 - mae: 0.1284 - val_loss: 0.3149 - val_mae: 0.3149\n",
      "Epoch 18/30\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.1261 - mae: 0.1261 - val_loss: 0.3067 - val_mae: 0.3067\n",
      "Epoch 19/30\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.3133 - val_mae: 0.3133\n",
      "Epoch 20/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.1227 - mae: 0.1227 - val_loss: 0.3236 - val_mae: 0.3236\n",
      "Epoch 21/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.3124 - val_mae: 0.3124\n",
      "Epoch 22/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.1194 - mae: 0.1194 - val_loss: 0.3141 - val_mae: 0.3141\n",
      "Epoch 23/30\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.1179 - mae: 0.1179 - val_loss: 0.3162 - val_mae: 0.3162\n",
      "Epoch 24/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.1163 - mae: 0.1163 - val_loss: 0.3157 - val_mae: 0.3157\n",
      "Epoch 25/30\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.1151 - mae: 0.1151 - val_loss: 0.3027 - val_mae: 0.3027\n",
      "Epoch 26/30\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.1138 - mae: 0.1138 - val_loss: 0.3074 - val_mae: 0.3074\n",
      "Epoch 27/30\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.1127 - mae: 0.1127 - val_loss: 0.3093 - val_mae: 0.3093\n",
      "Epoch 28/30\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.1115 - mae: 0.1115 - val_loss: 0.2975 - val_mae: 0.2975\n",
      "Epoch 29/30\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.1104 - mae: 0.1104 - val_loss: 0.3056 - val_mae: 0.3056\n",
      "Epoch 30/30\n",
      "769500/769500 [==============================] - 17s 22us/step - loss: 0.1091 - mae: 0.1091 - val_loss: 0.3054 - val_mae: 0.3054\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, epochs=30, batch_size=1000, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ddef382a48>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mae가 줄어드는 양상에서 오버피팅이 일어나는 것으로 추측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = scaler.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission 파일을 생성합니다.\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission = sample_sub+pred_test\n",
    "submission.to_csv('submission2_scaler.csv')   # 9.1956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표준정규화 적용 후 24.89 -> 9.19로 점수가 줄어듦.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hidden layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # model 초기화 \n",
    "model.add(Dense(units=452, activation='relu', input_dim=226))  # 첫번째 은닉층  # 226개 feature, 160개 뉴런, relu 함수를 활성화 함수로 사용\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=339, activation='relu'))   # 두번째 은닉층  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=226, activation='relu'))   # 두번째 은닉층  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=113, activation='relu'))   # 세번째 은닉층\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=4, activation='linear'))   # 출력층 (4개의 output을 도출해내야되기 때문에 units = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a0105\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/30\n",
      "769500/769500 [==============================] - 50s 65us/step - loss: 0.5492 - mae: 0.5492 - val_loss: 0.5195 - val_mae: 0.5195\n",
      "Epoch 2/30\n",
      "769500/769500 [==============================] - 49s 64us/step - loss: 0.3972 - mae: 0.3972 - val_loss: 0.4392 - val_mae: 0.4392\n",
      "Epoch 3/30\n",
      "769500/769500 [==============================] - 49s 64us/step - loss: 0.3386 - mae: 0.3386 - val_loss: 0.3788 - val_mae: 0.3788\n",
      "Epoch 4/30\n",
      "769500/769500 [==============================] - 47s 62us/step - loss: 0.3076 - mae: 0.3076 - val_loss: 0.3662 - val_mae: 0.3662\n",
      "Epoch 5/30\n",
      "769500/769500 [==============================] - 47s 61us/step - loss: 0.2889 - mae: 0.2889 - val_loss: 0.3398 - val_mae: 0.3398\n",
      "Epoch 6/30\n",
      "769500/769500 [==============================] - 49s 63us/step - loss: 0.2753 - mae: 0.2753 - val_loss: 0.3284 - val_mae: 0.3284\n",
      "Epoch 7/30\n",
      "769500/769500 [==============================] - 46s 60us/step - loss: 0.2660 - mae: 0.2660 - val_loss: 0.3194 - val_mae: 0.3194\n",
      "Epoch 8/30\n",
      "769500/769500 [==============================] - 52s 67us/step - loss: 0.2589 - mae: 0.2589 - val_loss: 0.3106 - val_mae: 0.3106\n",
      "Epoch 9/30\n",
      "769500/769500 [==============================] - 52s 68us/step - loss: 0.2528 - mae: 0.2528 - val_loss: 0.2985 - val_mae: 0.2985\n",
      "Epoch 10/30\n",
      "769500/769500 [==============================] - 627s 815us/step - loss: 0.2484 - mae: 0.2484 - val_loss: 0.3000 - val_mae: 0.3000\n",
      "Epoch 11/30\n",
      "769500/769500 [==============================] - 42s 54us/step - loss: 0.2438 - mae: 0.2438 - val_loss: 0.2857 - val_mae: 0.2857\n",
      "Epoch 12/30\n",
      "769500/769500 [==============================] - 46s 60us/step - loss: 0.2405 - mae: 0.2405 - val_loss: 0.2899 - val_mae: 0.2899\n",
      "Epoch 13/30\n",
      "769500/769500 [==============================] - 57s 74us/step - loss: 0.2378 - mae: 0.2378 - val_loss: 0.2848 - val_mae: 0.2848\n",
      "Epoch 14/30\n",
      "769500/769500 [==============================] - 58s 75us/step - loss: 0.2351 - mae: 0.2351 - val_loss: 0.2835 - val_mae: 0.2835\n",
      "Epoch 15/30\n",
      "769500/769500 [==============================] - 57s 74us/step - loss: 0.2329 - mae: 0.2329 - val_loss: 0.2847 - val_mae: 0.2847\n",
      "Epoch 16/30\n",
      "769500/769500 [==============================] - 56s 73us/step - loss: 0.2306 - mae: 0.2306 - val_loss: 0.2886 - val_mae: 0.2886\n",
      "Epoch 17/30\n",
      "769500/769500 [==============================] - 55s 72us/step - loss: 0.2291 - mae: 0.2291 - val_loss: 0.2886 - val_mae: 0.2886\n",
      "Epoch 18/30\n",
      "769500/769500 [==============================] - 57s 74us/step - loss: 0.2269 - mae: 0.2269 - val_loss: 0.2652 - val_mae: 0.2652\n",
      "Epoch 19/30\n",
      "769500/769500 [==============================] - 51s 67us/step - loss: 0.2256 - mae: 0.2256 - val_loss: 0.2575 - val_mae: 0.2575\n",
      "Epoch 20/30\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.2242 - mae: 0.2242 - val_loss: 0.2762 - val_mae: 0.2762\n",
      "Epoch 21/30\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 0.2229 - mae: 0.2229 - val_loss: 0.2804 - val_mae: 0.2804\n",
      "Epoch 22/30\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.2217 - mae: 0.2217 - val_loss: 0.2875 - val_mae: 0.2875\n",
      "Epoch 23/30\n",
      "769500/769500 [==============================] - 33s 42us/step - loss: 0.2204 - mae: 0.2204 - val_loss: 0.2504 - val_mae: 0.2504\n",
      "Epoch 24/30\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.2194 - mae: 0.2194 - val_loss: 0.2802 - val_mae: 0.2802\n",
      "Epoch 25/30\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 0.2184 - mae: 0.2184 - val_loss: 0.2702 - val_mae: 0.2702\n",
      "Epoch 26/30\n",
      "769500/769500 [==============================] - 33s 42us/step - loss: 0.2175 - mae: 0.2175 - val_loss: 0.2724 - val_mae: 0.2724\n",
      "Epoch 27/30\n",
      "769500/769500 [==============================] - 33s 42us/step - loss: 0.2166 - mae: 0.2166 - val_loss: 0.2629 - val_mae: 0.2629\n",
      "Epoch 28/30\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.2156 - mae: 0.2156 - val_loss: 0.2571 - val_mae: 0.2571\n",
      "Epoch 29/30\n",
      "769500/769500 [==============================] - 33s 42us/step - loss: 0.2144 - mae: 0.2144 - val_loss: 0.2696 - val_mae: 0.2696\n",
      "Epoch 30/30\n",
      "769500/769500 [==============================] - 33s 42us/step - loss: 0.2140 - mae: 0.2140 - val_loss: 0.2618 - val_mae: 0.2618\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, epochs=30, batch_size=1000, validation_split = 0.05)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f897827c8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden layer를 추가하고 dropout을 한 결과 오버피팅이 조금 해소된 것으로 보임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = scaler.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission 파일을 생성합니다.\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission = sample_sub+pred_test\n",
    "submission.to_csv('submission2_scaler_hidden_layer_add_drop_out.csv')  # 8.639 \n",
    "#submission.to_csv('submission2_scaler_hidden_layer_add.csv')   # 5.0256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout을 통해 오버피팅이 해소된 것으로 보였으나 dropout을 하지 않았을때의 성능이 더 좋음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epoch 수 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.3932 - mae: 0.3932 - val_loss: 0.4556 - val_mae: 0.4556\n",
      "Epoch 2/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.2339 - mae: 0.2339 - val_loss: 0.3896 - val_mae: 0.3896\n",
      "Epoch 3/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.1845 - mae: 0.1845 - val_loss: 0.3655 - val_mae: 0.3655\n",
      "Epoch 4/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.1575 - mae: 0.1575 - val_loss: 0.3336 - val_mae: 0.3336\n",
      "Epoch 5/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.1388 - mae: 0.1388 - val_loss: 0.3259 - val_mae: 0.3259\n",
      "Epoch 6/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.1262 - mae: 0.1262 - val_loss: 0.2982 - val_mae: 0.2982\n",
      "Epoch 7/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.1165 - mae: 0.1165 - val_loss: 0.2901 - val_mae: 0.2901\n",
      "Epoch 8/500\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 0.1083 - mae: 0.1083 - val_loss: 0.2801 - val_mae: 0.2801\n",
      "Epoch 9/500\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.1019 - mae: 0.1019 - val_loss: 0.2689 - val_mae: 0.2689\n",
      "Epoch 10/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0962 - mae: 0.0962 - val_loss: 0.2689 - val_mae: 0.2689\n",
      "Epoch 11/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0913 - mae: 0.0913 - val_loss: 0.2588 - val_mae: 0.2588\n",
      "Epoch 12/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0875 - mae: 0.0875 - val_loss: 0.2540 - val_mae: 0.2540\n",
      "Epoch 13/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0840 - mae: 0.0840 - val_loss: 0.2714 - val_mae: 0.2714\n",
      "Epoch 14/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0806 - mae: 0.0806 - val_loss: 0.2565 - val_mae: 0.2565\n",
      "Epoch 15/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0779 - mae: 0.0779 - val_loss: 0.2429 - val_mae: 0.2429\n",
      "Epoch 16/500\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.0753 - mae: 0.0753 - val_loss: 0.2418 - val_mae: 0.2418\n",
      "Epoch 17/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0732 - mae: 0.0732 - val_loss: 0.2325 - val_mae: 0.2325\n",
      "Epoch 18/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0708 - mae: 0.0708 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 19/500\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.2277 - val_mae: 0.2277\n",
      "Epoch 20/500\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.2285 - val_mae: 0.2285\n",
      "Epoch 21/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.2332 - val_mae: 0.2332\n",
      "Epoch 22/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.2184 - val_mae: 0.2184\n",
      "Epoch 23/500\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.2361 - val_mae: 0.2361\n",
      "Epoch 24/500\n",
      "769500/769500 [==============================] - 36s 46us/step - loss: 0.0620 - mae: 0.0620 - val_loss: 0.2293 - val_mae: 0.2293\n",
      "Epoch 25/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0609 - mae: 0.0609 - val_loss: 0.2242 - val_mae: 0.2242\n",
      "Epoch 26/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0596 - mae: 0.0596 - val_loss: 0.2319 - val_mae: 0.2319\n",
      "Epoch 27/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0591 - mae: 0.0591 - val_loss: 0.2215 - val_mae: 0.2215\n",
      "Epoch 28/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0580 - mae: 0.0580 - val_loss: 0.2230 - val_mae: 0.2230\n",
      "Epoch 29/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.2275 - val_mae: 0.2275\n",
      "Epoch 30/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0560 - mae: 0.0560 - val_loss: 0.2334 - val_mae: 0.2334\n",
      "Epoch 31/500\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.2310 - val_mae: 0.2310\n",
      "Epoch 32/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 33/500\n",
      "769500/769500 [==============================] - 30s 38us/step - loss: 0.0541 - mae: 0.0541 - val_loss: 0.2310 - val_mae: 0.2310\n",
      "Epoch 34/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0538 - mae: 0.0538 - val_loss: 0.2205 - val_mae: 0.2205\n",
      "Epoch 35/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0529 - mae: 0.0529 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 36/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.2237 - val_mae: 0.2237\n",
      "Epoch 37/500\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.0514 - mae: 0.0514 - val_loss: 0.2123 - val_mae: 0.2123\n",
      "Epoch 38/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0516 - mae: 0.0516 - val_loss: 0.2147 - val_mae: 0.2147\n",
      "Epoch 39/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0505 - mae: 0.0505 - val_loss: 0.2177 - val_mae: 0.2177 \n",
      "Epoch 40/500\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 0.0504 - mae: 0.0504 - val_loss: 0.2288 - val_mae: 0.2288\n",
      "Epoch 41/500\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 0.0498 - mae: 0.0498 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 42/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0496 - mae: 0.0496 - val_loss: 0.2228 - val_mae: 0.2228\n",
      "Epoch 43/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0491 - mae: 0.0491 - val_loss: 0.2163 - val_mae: 0.2163\n",
      "Epoch 44/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0487 - mae: 0.0487 - val_loss: 0.2080 - val_mae: 0.2080\n",
      "Epoch 45/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0482 - mae: 0.0482 - val_loss: 0.2154 - val_mae: 0.2154\n",
      "Epoch 46/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0477 - mae: 0.0477 - val_loss: 0.2066 - val_mae: 0.2066\n",
      "Epoch 47/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0473 - mae: 0.0473 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 48/500\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 0.0472 - mae: 0.0472 - val_loss: 0.2026 - val_mae: 0.2026\n",
      "Epoch 49/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0466 - mae: 0.0466 - val_loss: 0.2217 - val_mae: 0.2217\n",
      "Epoch 50/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0464 - mae: 0.0464 - val_loss: 0.2049 - val_mae: 0.2049\n",
      "Epoch 51/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0462 - mae: 0.0462 - val_loss: 0.2186 - val_mae: 0.2186\n",
      "Epoch 52/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0460 - mae: 0.0460 - val_loss: 0.2175 - val_mae: 0.2175\n",
      "Epoch 53/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.2140 - val_mae: 0.2140\n",
      "Epoch 54/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.2043 - val_mae: 0.2043\n",
      "Epoch 55/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0451 - mae: 0.0451 - val_loss: 0.2051 - val_mae: 0.2051\n",
      "Epoch 56/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0446 - mae: 0.0446 - val_loss: 0.2084 - val_mae: 0.2084\n",
      "Epoch 57/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.2094 - val_mae: 0.2094\n",
      "Epoch 58/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0442 - mae: 0.0442 - val_loss: 0.2109 - val_mae: 0.2109\n",
      "Epoch 59/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.2104 - val_mae: 0.2104\n",
      "Epoch 60/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0437 - mae: 0.0437 - val_loss: 0.2116 - val_mae: 0.2116\n",
      "Epoch 61/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0436 - mae: 0.0436 - val_loss: 0.2095 - val_mae: 0.2095\n",
      "Epoch 62/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0432 - mae: 0.0432 - val_loss: 0.2048 - val_mae: 0.2048\n",
      "Epoch 63/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0432 - mae: 0.0432 - val_loss: 0.2105 - val_mae: 0.2105\n",
      "Epoch 64/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0430 - mae: 0.0430 - val_loss: 0.2028 - val_mae: 0.2028\n",
      "Epoch 65/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0426 - mae: 0.0426 - val_loss: 0.2085 - val_mae: 0.2085\n",
      "Epoch 66/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0425 - mae: 0.0425 - val_loss: 0.1984 - val_mae: 0.1984\n",
      "Epoch 67/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0422 - mae: 0.0422 - val_loss: 0.2137 - val_mae: 0.2137: 1s\n",
      "Epoch 68/500\n",
      "769500/769500 [==============================] - 23s 31us/step - loss: 0.0419 - mae: 0.0419 - val_loss: 0.1976 - val_mae: 0.1976\n",
      "Epoch 69/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0419 - mae: 0.0419 - val_loss: 0.2110 - val_mae: 0.2110\n",
      "Epoch 70/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0417 - mae: 0.0417 - val_loss: 0.2138 - val_mae: 0.2138\n",
      "Epoch 71/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0415 - mae: 0.0415 - val_loss: 0.2080 - val_mae: 0.2080\n",
      "Epoch 72/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0413 - mae: 0.0413 - val_loss: 0.2119 - val_mae: 0.2119\n",
      "Epoch 73/500\n",
      "769500/769500 [==============================] - 27s 34us/step - loss: 0.0411 - mae: 0.0411 - val_loss: 0.2010 - val_mae: 0.2010\n",
      "Epoch 74/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0412 - mae: 0.0412 - val_loss: 0.1998 - val_mae: 0.1998\n",
      "Epoch 75/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0410 - mae: 0.0410 - val_loss: 0.1980 - val_mae: 0.1980\n",
      "Epoch 76/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0408 - mae: 0.0408 - val_loss: 0.1932 - val_mae: 0.1932\n",
      "Epoch 77/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0406 - mae: 0.0406 - val_loss: 0.2074 - val_mae: 0.2074\n",
      "Epoch 78/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0401 - mae: 0.0401 - val_loss: 0.1941 - val_mae: 0.1941\n",
      "Epoch 79/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0407 - mae: 0.0407 - val_loss: 0.1985 - val_mae: 0.1985\n",
      "Epoch 80/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0399 - mae: 0.0399 - val_loss: 0.2109 - val_mae: 0.2109\n",
      "Epoch 81/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0397 - mae: 0.0397 - val_loss: 0.1940 - val_mae: 0.1940\n",
      "Epoch 82/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.1910 - val_mae: 0.1910\n",
      "Epoch 83/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0399 - mae: 0.0399 - val_loss: 0.1950 - val_mae: 0.1950\n",
      "Epoch 84/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0394 - mae: 0.0394 - val_loss: 0.2109 - val_mae: 0.2109\n",
      "Epoch 85/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0395 - mae: 0.0395 - val_loss: 0.1878 - val_mae: 0.1878\n",
      "Epoch 86/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.2071 - val_mae: 0.2071\n",
      "Epoch 87/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0390 - mae: 0.0390 - val_loss: 0.1995 - val_mae: 0.1995\n",
      "Epoch 88/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0391 - mae: 0.0391 - val_loss: 0.2009 - val_mae: 0.2009\n",
      "Epoch 89/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0387 - mae: 0.0387 - val_loss: 0.2018 - val_mae: 0.2018\n",
      "Epoch 90/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0387 - mae: 0.0387 - val_loss: 0.2020 - val_mae: 0.2020\n",
      "Epoch 91/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0389 - mae: 0.0389 - val_loss: 0.2079 - val_mae: 0.2079\n",
      "Epoch 92/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0387 - mae: 0.0387 - val_loss: 0.1984 - val_mae: 0.1984\n",
      "Epoch 93/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0384 - mae: 0.0384 - val_loss: 0.2138 - val_mae: 0.2138\n",
      "Epoch 94/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0382 - mae: 0.0382 - val_loss: 0.1989 - val_mae: 0.1989\n",
      "Epoch 95/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0385 - mae: 0.0385 - val_loss: 0.1959 - val_mae: 0.1959\n",
      "Epoch 96/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0377 - mae: 0.0377 - val_loss: 0.2042 - val_mae: 0.2042\n",
      "Epoch 97/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0379 - mae: 0.0379 - val_loss: 0.2086 - val_mae: 0.2086\n",
      "Epoch 98/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0380 - mae: 0.0380 - val_loss: 0.1915 - val_mae: 0.1915\n",
      "Epoch 99/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0376 - mae: 0.0376 - val_loss: 0.1977 - val_mae: 0.1977\n",
      "Epoch 100/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0378 - mae: 0.0378 - val_loss: 0.1985 - val_mae: 0.1985\n",
      "Epoch 101/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0376 - mae: 0.0376 - val_loss: 0.2101 - val_mae: 0.2101\n",
      "Epoch 102/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0374 - mae: 0.0374 - val_loss: 0.2081 - val_mae: 0.2081\n",
      "Epoch 103/500\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 0.0370 - mae: 0.0370 - val_loss: 0.1959 - val_mae: 0.1959\n",
      "Epoch 104/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0373 - mae: 0.0373 - val_loss: 0.2125 - val_mae: 0.2125\n",
      "Epoch 105/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0369 - mae: 0.0369 - val_loss: 0.2048 - val_mae: 0.2048- ETA: 0s - loss: 0.0369 - mae: 0.0\n",
      "Epoch 106/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0371 - mae: 0.0371 - val_loss: 0.2001 - val_mae: 0.2001\n",
      "Epoch 107/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0369 - mae: 0.0369 - val_loss: 0.2000 - val_mae: 0.2000\n",
      "Epoch 108/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0367 - mae: 0.0367 - val_loss: 0.1977 - val_mae: 0.1977\n",
      "Epoch 109/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0369 - mae: 0.0369 - val_loss: 0.2123 - val_mae: 0.2123\n",
      "Epoch 110/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0368 - mae: 0.0368 - val_loss: 0.1940 - val_mae: 0.1940\n",
      "Epoch 111/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0365 - mae: 0.0365 - val_loss: 0.1998 - val_mae: 0.1998\n",
      "Epoch 112/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0367 - mae: 0.0367 - val_loss: 0.1994 - val_mae: 0.1994\n",
      "Epoch 113/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0365 - mae: 0.0365 - val_loss: 0.2081 - val_mae: 0.2081\n",
      "Epoch 114/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0362 - mae: 0.0362 - val_loss: 0.2150 - val_mae: 0.2150\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 23s 31us/step - loss: 0.0362 - mae: 0.0362 - val_loss: 0.2007 - val_mae: 0.2007\n",
      "Epoch 116/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.2002 - val_mae: 0.20020360 - m\n",
      "Epoch 117/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.2035 - val_mae: 0.2035\n",
      "Epoch 118/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0358 - mae: 0.0358 - val_loss: 0.2076 - val_mae: 0.2076\n",
      "Epoch 119/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0359 - mae: 0.0359 - val_loss: 0.1940 - val_mae: 0.1940\n",
      "Epoch 120/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0355 - mae: 0.0355 - val_loss: 0.2074 - val_mae: 0.2074\n",
      "Epoch 121/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0358 - mae: 0.0358 - val_loss: 0.1991 - val_mae: 0.1991\n",
      "Epoch 122/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0356 - mae: 0.0356 - val_loss: 0.2044 - val_mae: 0.2044\n",
      "Epoch 123/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0352 - mae: 0.0352 - val_loss: 0.1922 - val_mae: 0.1922\n",
      "Epoch 124/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0355 - mae: 0.0355 - val_loss: 0.1950 - val_mae: 0.1950\n",
      "Epoch 125/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0353 - mae: 0.0353 - val_loss: 0.2113 - val_mae: 0.2113\n",
      "Epoch 126/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0353 - mae: 0.0353 - val_loss: 0.2044 - val_mae: 0.2044\n",
      "Epoch 127/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0353 - mae: 0.0353 - val_loss: 0.2103 - val_mae: 0.2103\n",
      "Epoch 128/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.2011 - val_mae: 0.2011\n",
      "Epoch 129/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.2072 - val_mae: 0.2072\n",
      "Epoch 130/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0351 - mae: 0.0351 - val_loss: 0.1953 - val_mae: 0.1953\n",
      "Epoch 131/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.1936 - val_mae: 0.1936\n",
      "Epoch 132/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.1981 - val_mae: 0.1981\n",
      "Epoch 133/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0344 - mae: 0.0344 - val_loss: 0.1952 - val_mae: 0.1952\n",
      "Epoch 134/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.1971 - val_mae: 0.1971\n",
      "Epoch 135/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0348 - mae: 0.0348 - val_loss: 0.1997 - val_mae: 0.1997\n",
      "Epoch 136/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0346 - mae: 0.0346 - val_loss: 0.1937 - val_mae: 0.1937\n",
      "Epoch 137/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0345 - mae: 0.0345 - val_loss: 0.2070 - val_mae: 0.2070\n",
      "Epoch 138/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0344 - mae: 0.0344 - val_loss: 0.2054 - val_mae: 0.2054\n",
      "Epoch 139/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0343 - mae: 0.0343 - val_loss: 0.2096 - val_mae: 0.2096\n",
      "Epoch 140/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0341 - mae: 0.0341 - val_loss: 0.2058 - val_mae: 0.2058\n",
      "Epoch 141/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0345 - mae: 0.0345 - val_loss: 0.2085 - val_mae: 0.2085\n",
      "Epoch 142/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0345 - mae: 0.0345 - val_loss: 0.2004 - val_mae: 0.2004\n",
      "Epoch 143/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0338 - mae: 0.0338 - val_loss: 0.2040 - val_mae: 0.2040\n",
      "Epoch 144/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0343 - mae: 0.0343 - val_loss: 0.1945 - val_mae: 0.1945\n",
      "Epoch 145/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0340 - mae: 0.0340 - val_loss: 0.2140 - val_mae: 0.2140\n",
      "Epoch 146/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0338 - mae: 0.0338 - val_loss: 0.1922 - val_mae: 0.1922\n",
      "Epoch 147/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0340 - mae: 0.0340 - val_loss: 0.1997 - val_mae: 0.1997\n",
      "Epoch 148/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.2053 - val_mae: 0.2053\n",
      "Epoch 149/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0338 - mae: 0.0338 - val_loss: 0.2051 - val_mae: 0.2051\n",
      "Epoch 150/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0335 - mae: 0.0335 - val_loss: 0.1958 - val_mae: 0.1958\n",
      "Epoch 151/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.2140 - val_mae: 0.2140\n",
      "Epoch 152/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.1994 - val_mae: 0.1994\n",
      "Epoch 153/500\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.2044 - val_mae: 0.2044\n",
      "Epoch 154/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0333 - mae: 0.0333 - val_loss: 0.1931 - val_mae: 0.1931\n",
      "Epoch 155/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0335 - mae: 0.0335 - val_loss: 0.1941 - val_mae: 0.1941\n",
      "Epoch 156/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0335 - mae: 0.0335 - val_loss: 0.1913 - val_mae: 0.1913\n",
      "Epoch 157/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0335 - mae: 0.0335 - val_loss: 0.1991 - val_mae: 0.1991\n",
      "Epoch 158/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.1949 - val_mae: 0.1949\n",
      "Epoch 159/500\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 0.0332 - mae: 0.0332 - val_loss: 0.1986 - val_mae: 0.1986\n",
      "Epoch 160/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.1983 - val_mae: 0.1983\n",
      "Epoch 161/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0333 - mae: 0.0333 - val_loss: 0.1980 - val_mae: 0.1980\n",
      "Epoch 162/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0329 - mae: 0.0329 - val_loss: 0.2008 - val_mae: 0.2008\n",
      "Epoch 163/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0330 - mae: 0.0330 - val_loss: 0.2082 - val_mae: 0.2082\n",
      "Epoch 164/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.2121 - val_mae: 0.2121\n",
      "Epoch 165/500\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.0328 - mae: 0.0328 - val_loss: 0.2181 - val_mae: 0.2181\n",
      "Epoch 166/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.2021 - val_mae: 0.2021\n",
      "Epoch 167/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0325 - mae: 0.0325 - val_loss: 0.2098 - val_mae: 0.2098\n",
      "Epoch 168/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0327 - mae: 0.0327 - val_loss: 0.1967 - val_mae: 0.1967\n",
      "Epoch 169/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0329 - mae: 0.0329 - val_loss: 0.1876 - val_mae: 0.1876\n",
      "Epoch 170/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0325 - mae: 0.0325 - val_loss: 0.1978 - val_mae: 0.1978\n",
      "Epoch 171/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0326 - mae: 0.0326 - val_loss: 0.2100 - val_mae: 0.2100\n",
      "Epoch 172/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0326 - mae: 0.0326 - val_loss: 0.2044 - val_mae: 0.2044\n",
      "Epoch 173/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0323 - mae: 0.0323 - val_loss: 0.2120 - val_mae: 0.2120\n",
      "Epoch 174/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0325 - mae: 0.0325 - val_loss: 0.1932 - val_mae: 0.1932\n",
      "Epoch 175/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0325 - mae: 0.0325 - val_loss: 0.1934 - val_mae: 0.1934ae:  - ETA: 1s - loss: 0.0\n",
      "Epoch 176/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0326 - mae: 0.0326 - val_loss: 0.1866 - val_mae: 0.1866\n",
      "Epoch 177/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0323 - mae: 0.0323 - val_loss: 0.1953 - val_mae: 0.1953\n",
      "Epoch 178/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0322 - mae: 0.0322 - val_loss: 0.2062 - val_mae: 0.2062\n",
      "Epoch 179/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0321 - mae: 0.0321 - val_loss: 0.1832 - val_mae: 0.1832\n",
      "Epoch 180/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0322 - mae: 0.0322 - val_loss: 0.1974 - val_mae: 0.1974\n",
      "Epoch 181/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0321 - mae: 0.0321 - val_loss: 0.2050 - val_mae: 0.2050\n",
      "Epoch 182/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0323 - mae: 0.0323 - val_loss: 0.2073 - val_mae: 0.2073\n",
      "Epoch 183/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0320 - mae: 0.0320 - val_loss: 0.1923 - val_mae: 0.1923ae: - ETA: 1s - l\n",
      "Epoch 184/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0321 - mae: 0.0321 - val_loss: 0.1948 - val_mae: 0.1948\n",
      "Epoch 185/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0319 - mae: 0.0319 - val_loss: 0.2059 - val_mae: 0.2059\n",
      "Epoch 186/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0321 - mae: 0.0321 - val_loss: 0.1950 - val_mae: 0.1950\n",
      "Epoch 187/500\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 0.0317 - mae: 0.0317 - val_loss: 0.2011 - val_mae: 0.2011\n",
      "Epoch 188/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0321 - mae: 0.0321 - val_loss: 0.1954 - val_mae: 0.1954\n",
      "Epoch 189/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0316 - mae: 0.0316 - val_loss: 0.2013 - val_mae: 0.2013\n",
      "Epoch 190/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0316 - mae: 0.0316 - val_loss: 0.2026 - val_mae: 0.2026\n",
      "Epoch 191/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0317 - mae: 0.0317 - val_loss: 0.2063 - val_mae: 0.2063\n",
      "Epoch 192/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0318 - mae: 0.0318 - val_loss: 0.1917 - val_mae: 0.1917\n",
      "Epoch 193/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0318 - mae: 0.0318 - val_loss: 0.1894 - val_mae: 0.1894\n",
      "Epoch 194/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.2009 - val_mae: 0.2009\n",
      "Epoch 195/500\n",
      "769500/769500 [==============================] - 32s 42us/step - loss: 0.0317 - mae: 0.0317 - val_loss: 0.2018 - val_mae: 0.2018\n",
      "Epoch 196/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0315 - mae: 0.0315 - val_loss: 0.1997 - val_mae: 0.1997\n",
      "Epoch 197/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0317 - mae: 0.0317 - val_loss: 0.1987 - val_mae: 0.1987\n",
      "Epoch 198/500\n",
      "769500/769500 [==============================] - 31s 40us/step - loss: 0.0316 - mae: 0.0316 - val_loss: 0.1974 - val_mae: 0.1974\n",
      "Epoch 199/500\n",
      "769500/769500 [==============================] - 27s 36us/step - loss: 0.0318 - mae: 0.0318 - val_loss: 0.2108 - val_mae: 0.2108\n",
      "Epoch 200/500\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 0.0311 - mae: 0.0311 - val_loss: 0.2104 - val_mae: 0.2104\n",
      "Epoch 201/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0316 - mae: 0.0316 - val_loss: 0.1971 - val_mae: 0.1971\n",
      "Epoch 202/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0311 - mae: 0.0311 - val_loss: 0.2016 - val_mae: 0.2016\n",
      "Epoch 203/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.1978 - val_mae: 0.1978\n",
      "Epoch 204/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0315 - mae: 0.0315 - val_loss: 0.2018 - val_mae: 0.2018\n",
      "Epoch 205/500\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 0.0311 - mae: 0.0311 - val_loss: 0.1887 - val_mae: 0.1887\n",
      "Epoch 206/500\n",
      "769500/769500 [==============================] - 31s 41us/step - loss: 0.0313 - mae: 0.0313 - val_loss: 0.1909 - val_mae: 0.1909\n",
      "Epoch 207/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0311 - mae: 0.0311 - val_loss: 0.2071 - val_mae: 0.2071\n",
      "Epoch 208/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.2020 - val_mae: 0.2020\n",
      "Epoch 209/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0311 - mae: 0.0311 - val_loss: 0.2073 - val_mae: 0.2073\n",
      "Epoch 210/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0312 - mae: 0.0312 - val_loss: 0.2000 - val_mae: 0.2000\n",
      "Epoch 211/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0309 - mae: 0.0309 - val_loss: 0.1912 - val_mae: 0.1912\n",
      "Epoch 212/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0309 - mae: 0.0309 - val_loss: 0.1920 - val_mae: 0.1920\n",
      "Epoch 213/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0309 - mae: 0.0309 - val_loss: 0.1970 - val_mae: 0.1970\n",
      "Epoch 214/500\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.0310 - mae: 0.0310 - val_loss: 0.1997 - val_mae: 0.1997\n",
      "Epoch 215/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0311 - mae: 0.0311 - val_loss: 0.2028 - val_mae: 0.2028\n",
      "Epoch 216/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0308 - mae: 0.0308 - val_loss: 0.2069 - val_mae: 0.2069\n",
      "Epoch 217/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0309 - mae: 0.0309 - val_loss: 0.1968 - val_mae: 0.1968\n",
      "Epoch 218/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0308 - mae: 0.0308 - val_loss: 0.2060 - val_mae: 0.2060\n",
      "Epoch 219/500\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 0.0312 - mae: 0.0312 - val_loss: 0.1905 - val_mae: 0.1905\n",
      "Epoch 220/500\n",
      "769500/769500 [==============================] - 28s 37us/step - loss: 0.0307 - mae: 0.0307 - val_loss: 0.2048 - val_mae: 0.2048\n",
      "Epoch 221/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0306 - mae: 0.0306 - val_loss: 0.1972 - val_mae: 0.1972\n",
      "Epoch 222/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0308 - mae: 0.0308 - val_loss: 0.1991 - val_mae: 0.1991\n",
      "Epoch 223/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0306 - mae: 0.0306 - val_loss: 0.2025 - val_mae: 0.2025\n",
      "Epoch 224/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0305 - mae: 0.0305 - val_loss: 0.2021 - val_mae: 0.2021\n",
      "Epoch 225/500\n",
      "769500/769500 [==============================] - 31s 41us/step - loss: 0.0306 - mae: 0.0306 - val_loss: 0.2018 - val_mae: 0.2018\n",
      "Epoch 226/500\n",
      "769500/769500 [==============================] - 29s 38us/step - loss: 0.0309 - mae: 0.0309 - val_loss: 0.1984 - val_mae: 0.1984\n",
      "Epoch 227/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0307 - mae: 0.0307 - val_loss: 0.2093 - val_mae: 0.2093\n",
      "Epoch 228/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0307 - mae: 0.0307 - val_loss: 0.1978 - val_mae: 0.1978\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0304 - mae: 0.0304 - val_loss: 0.1957 - val_mae: 0.1957\n",
      "Epoch 230/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.2045 - val_mae: 0.2045\n",
      "Epoch 231/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0310 - mae: 0.0310 - val_loss: 0.2034 - val_mae: 0.2034\n",
      "Epoch 232/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0304 - mae: 0.0304 - val_loss: 0.2036 - val_mae: 0.2036\n",
      "Epoch 233/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.1950 - val_mae: 0.1950\n",
      "Epoch 234/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.2030 - val_mae: 0.2030\n",
      "Epoch 235/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0306 - mae: 0.0306 - val_loss: 0.1932 - val_mae: 0.1932\n",
      "Epoch 236/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0304 - mae: 0.0304 - val_loss: 0.1935 - val_mae: 0.1935\n",
      "Epoch 237/500\n",
      "769500/769500 [==============================] - 30s 39us/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.2078 - val_mae: 0.2078\n",
      "Epoch 238/500\n",
      "769500/769500 [==============================] - 32s 41us/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.1989 - val_mae: 0.1989\n",
      "Epoch 239/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.1987 - val_mae: 0.1987\n",
      "Epoch 240/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.1946 - val_mae: 0.1946\n",
      "Epoch 241/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0304 - mae: 0.0304 - val_loss: 0.1947 - val_mae: 0.1947\n",
      "Epoch 242/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.2107 - val_mae: 0.2107\n",
      "Epoch 243/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0304 - mae: 0.0304 - val_loss: 0.1907 - val_mae: 0.1907\n",
      "Epoch 244/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.2059 - val_mae: 0.2059\n",
      "Epoch 245/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.2004 - val_mae: 0.2004\n",
      "Epoch 246/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0302 - mae: 0.0302 - val_loss: 0.1928 - val_mae: 0.1928\n",
      "Epoch 247/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.1927 - val_mae: 0.1927\n",
      "Epoch 248/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0300 - mae: 0.0300 - val_loss: 0.1922 - val_mae: 0.1922\n",
      "Epoch 249/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.2052 - val_mae: 0.2052\n",
      "Epoch 250/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.1968 - val_mae: 0.1968\n",
      "Epoch 251/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.2033 - val_mae: 0.2033\n",
      "Epoch 252/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.2040 - val_mae: 0.2040\n",
      "Epoch 253/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0302 - mae: 0.0302 - val_loss: 0.2044 - val_mae: 0.2044\n",
      "Epoch 254/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.2008 - val_mae: 0.2008\n",
      "Epoch 255/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.1955 - val_mae: 0.1955\n",
      "Epoch 256/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.1997 - val_mae: 0.1997\n",
      "Epoch 257/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.1976 - val_mae: 0.1976\n",
      "Epoch 258/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.2066 - val_mae: 0.2066\n",
      "Epoch 259/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.2047 - val_mae: 0.2047\n",
      "Epoch 260/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.2013 - val_mae: 0.2013\n",
      "Epoch 261/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.2006 - val_mae: 0.2006\n",
      "Epoch 262/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.1986 - val_mae: 0.1986\n",
      "Epoch 263/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0296 - mae: 0.0296 - val_loss: 0.2023 - val_mae: 0.2023\n",
      "Epoch 264/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0297 - mae: 0.0297 - val_loss: 0.2124 - val_mae: 0.2124\n",
      "Epoch 265/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0294 - mae: 0.0294 - val_loss: 0.2136 - val_mae: 0.2136\n",
      "Epoch 266/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0296 - mae: 0.0296 - val_loss: 0.1969 - val_mae: 0.1969\n",
      "Epoch 267/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.1914 - val_mae: 0.1914\n",
      "Epoch 268/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0297 - mae: 0.0297 - val_loss: 0.1969 - val_mae: 0.19690.0297 - mae: 0.0\n",
      "Epoch 269/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0296 - mae: 0.0296 - val_loss: 0.1962 - val_mae: 0.1962\n",
      "Epoch 270/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.1989 - val_mae: 0.1989\n",
      "Epoch 271/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.2074 - val_mae: 0.2074\n",
      "Epoch 272/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0297 - mae: 0.0297 - val_loss: 0.1955 - val_mae: 0.1955\n",
      "Epoch 273/500\n",
      "769500/769500 [==============================] - 29s 37us/step - loss: 0.0294 - mae: 0.0294 - val_loss: 0.2243 - val_mae: 0.2243\n",
      "Epoch 274/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.2064 - val_mae: 0.2064\n",
      "Epoch 275/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.2026 - val_mae: 0.2026\n",
      "Epoch 276/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.2143 - val_mae: 0.2143\n",
      "Epoch 277/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0294 - mae: 0.0294 - val_loss: 0.2152 - val_mae: 0.2152\n",
      "Epoch 278/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.2077 - val_mae: 0.2077\n",
      "Epoch 279/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.2145 - val_mae: 0.2145\n",
      "Epoch 280/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0292 - mae: 0.0292 - val_loss: 0.1983 - val_mae: 0.1983\n",
      "Epoch 281/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.1944 - val_mae: 0.1944\n",
      "Epoch 282/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.1974 - val_mae: 0.1974\n",
      "Epoch 283/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0294 - mae: 0.0294 - val_loss: 0.2009 - val_mae: 0.2009\n",
      "Epoch 284/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0294 - mae: 0.0294 - val_loss: 0.1962 - val_mae: 0.1962\n",
      "Epoch 285/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0292 - mae: 0.0292 - val_loss: 0.1996 - val_mae: 0.1996\n",
      "Epoch 286/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.1940 - val_mae: 0.1940\n",
      "Epoch 287/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.2124 - val_mae: 0.2124\n",
      "Epoch 288/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0292 - mae: 0.0292 - val_loss: 0.1855 - val_mae: 0.1855\n",
      "Epoch 289/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.2050 - val_mae: 0.2050\n",
      "Epoch 290/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.2102 - val_mae: 0.2102\n",
      "Epoch 291/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.2053 - val_mae: 0.2053\n",
      "Epoch 292/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.1986 - val_mae: 0.1986\n",
      "Epoch 293/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.1903 - val_mae: 0.1903\n",
      "Epoch 294/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0294 - mae: 0.0294 - val_loss: 0.1946 - val_mae: 0.1946\n",
      "Epoch 295/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.1916 - val_mae: 0.1916\n",
      "Epoch 296/500\n",
      "769500/769500 [==============================] - 23s 31us/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.2077 - val_mae: 0.2077\n",
      "Epoch 297/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.1956 - val_mae: 0.1956\n",
      "Epoch 298/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.2092 - val_mae: 0.2092\n",
      "Epoch 299/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.2052 - val_mae: 0.2052\n",
      "Epoch 300/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.2149 - val_mae: 0.2149\n",
      "Epoch 301/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.2056 - val_mae: 0.2056\n",
      "Epoch 302/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.2052 - val_mae: 0.2052\n",
      "Epoch 303/500\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.2039 - val_mae: 0.2039\n",
      "Epoch 304/500\n",
      "769500/769500 [==============================] - 33s 43us/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.2080 - val_mae: 0.2080\n",
      "Epoch 305/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.1914 - val_mae: 0.1914\n",
      "Epoch 306/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.1893 - val_mae: 0.1893\n",
      "Epoch 307/500\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 0.0286 - mae: 0.0286 - val_loss: 0.1975 - val_mae: 0.1975\n",
      "Epoch 308/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.2087 - val_mae: 0.2087\n",
      "Epoch 309/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.1975 - val_mae: 0.1975\n",
      "Epoch 310/500\n",
      "769500/769500 [==============================] - 27s 34us/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.2004 - val_mae: 0.2004\n",
      "Epoch 311/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0286 - mae: 0.0286 - val_loss: 0.2085 - val_mae: 0.2085\n",
      "Epoch 312/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0288 - mae: 0.0288 - val_loss: 0.2052 - val_mae: 0.2052\n",
      "Epoch 313/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.2065 - val_mae: 0.2065\n",
      "Epoch 314/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0288 - mae: 0.0288 - val_loss: 0.1988 - val_mae: 0.1988\n",
      "Epoch 315/500\n",
      "769500/769500 [==============================] - 27s 35us/step - loss: 0.0286 - mae: 0.0286 - val_loss: 0.2085 - val_mae: 0.2085\n",
      "Epoch 316/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.2060 - val_mae: 0.2060\n",
      "Epoch 317/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.1902 - val_mae: 0.1902\n",
      "Epoch 318/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.2027 - val_mae: 0.2027\n",
      "Epoch 319/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2144 - val_mae: 0.2144\n",
      "Epoch 320/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0288 - mae: 0.0288 - val_loss: 0.2058 - val_mae: 0.2058\n",
      "Epoch 321/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0286 - mae: 0.0286 - val_loss: 0.2055 - val_mae: 0.2055\n",
      "Epoch 322/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.1955 - val_mae: 0.1955\n",
      "Epoch 323/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.1975 - val_mae: 0.1975\n",
      "Epoch 324/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.2154 - val_mae: 0.2154\n",
      "Epoch 325/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.2048 - val_mae: 0.2048\n",
      "Epoch 326/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.1922 - val_mae: 0.1922\n",
      "Epoch 327/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.2031 - val_mae: 0.2031\n",
      "Epoch 328/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.2010 - val_mae: 0.2010\n",
      "Epoch 329/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.1901 - val_mae: 0.1901l\n",
      "Epoch 330/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2139 - val_mae: 0.2139\n",
      "Epoch 331/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0286 - mae: 0.0286 - val_loss: 0.1972 - val_mae: 0.1972\n",
      "Epoch 332/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.2025 - val_mae: 0.2025\n",
      "Epoch 333/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.2047 - val_mae: 0.2047\n",
      "Epoch 334/500\n",
      "769500/769500 [==============================] - 26s 33us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.2043 - val_mae: 0.2043\n",
      "Epoch 335/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.1957 - val_mae: 0.1957\n",
      "Epoch 336/500\n",
      "769500/769500 [==============================] - 26s 34us/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.1969 - val_mae: 0.1969\n",
      "Epoch 337/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.2065 - val_mae: 0.2065\n",
      "Epoch 338/500\n",
      "769500/769500 [==============================] - 28s 36us/step - loss: 0.0286 - mae: 0.0286 - val_loss: 0.2021 - val_mae: 0.2021\n",
      "Epoch 339/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.2017 - val_mae: 0.2017\n",
      "Epoch 340/500\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.2019 - val_mae: 0.2019: 0.0282 - mae: 0 - ETA: \n",
      "Epoch 341/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.1906 - val_mae: 0.1906\n",
      "Epoch 342/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.2151 - val_mae: 0.2151\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.2010 - val_mae: 0.2010\n",
      "Epoch 344/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.1923 - val_mae: 0.1923\n",
      "Epoch 345/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2063 - val_mae: 0.2063\n",
      "Epoch 346/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2031 - val_mae: 0.2031\n",
      "Epoch 347/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2001 - val_mae: 0.2001\n",
      "Epoch 348/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.2076 - val_mae: 0.2076\n",
      "Epoch 349/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.2022 - val_mae: 0.2022s - loss: 0.0281  - ETA: 0s - loss: 0.0281 - ma\n",
      "Epoch 350/500\n",
      "769500/769500 [==============================] - 25s 33us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.1926 - val_mae: 0.1926\n",
      "Epoch 351/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.2014 - val_mae: 0.2014\n",
      "Epoch 352/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2039 - val_mae: 0.2039 - ETA: 0s - loss: 0.0282 - mae: 0\n",
      "Epoch 353/500\n",
      "769500/769500 [==============================] - 25s 32us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2055 - val_mae: 0.2055\n",
      "Epoch 354/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.1997 - val_mae: 0.1997\n",
      "Epoch 355/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.2076 - val_mae: 0.2076 - - E\n",
      "Epoch 356/500\n",
      "769500/769500 [==============================] - 24s 31us/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.2160 - val_mae: 0.2160\n",
      "Epoch 357/500\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.1916 - val_mae: 0.1916\n",
      "Epoch 358/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.2140 - val_mae: 0.2140\n",
      "Epoch 359/500\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 360/500\n",
      "769500/769500 [==============================] - 30s 38us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.2172 - val_mae: 0.2172\n",
      "Epoch 361/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2021 - val_mae: 0.2021\n",
      "Epoch 362/500\n",
      "769500/769500 [==============================] - 33s 42us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2107 - val_mae: 0.2107\n",
      "Epoch 363/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2080 - val_mae: 0.2080\n",
      "Epoch 364/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.2107 - val_mae: 0.2107\n",
      "Epoch 365/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.1931 - val_mae: 0.1931\n",
      "Epoch 366/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.1985 - val_mae: 0.1985\n",
      "Epoch 367/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.1971 - val_mae: 0.1971\n",
      "Epoch 368/500\n",
      "769500/769500 [==============================] - 36s 47us/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.2020 - val_mae: 0.2020\n",
      "Epoch 369/500\n",
      "769500/769500 [==============================] - 33s 44us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.2089 - val_mae: 0.2089\n",
      "Epoch 370/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2090 - val_mae: 0.2090\n",
      "Epoch 371/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.2103 - val_mae: 0.2103\n",
      "Epoch 372/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2069 - val_mae: 0.2069\n",
      "Epoch 373/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2091 - val_mae: 0.2091\n",
      "Epoch 374/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.1957 - val_mae: 0.1957\n",
      "Epoch 375/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.2090 - val_mae: 0.2090- loss: 0.0277 - mae: \n",
      "Epoch 376/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.1982 - val_mae: 0.1982.0279 - ma - ET\n",
      "Epoch 377/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.1951 - val_mae: 0.1951\n",
      "Epoch 378/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.2134 - val_mae: 0.2134\n",
      "Epoch 379/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.1956 - val_mae: 0.1956\n",
      "Epoch 380/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.1996 - val_mae: 0.1996\n",
      "Epoch 381/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.2078 - val_mae: 0.2078\n",
      "Epoch 382/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.1977 - val_mae: 0.1977\n",
      "Epoch 383/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.2057 - val_mae: 0.2057\n",
      "Epoch 384/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.2065 - val_mae: 0.2065\n",
      "Epoch 385/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.2248 - val_mae: 0.2248\n",
      "Epoch 386/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.2139 - val_mae: 0.2139\n",
      "Epoch 387/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2151 - val_mae: 0.2151\n",
      "Epoch 388/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2058 - val_mae: 0.2058\n",
      "Epoch 389/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.2041 - val_mae: 0.2041\n",
      "Epoch 390/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.2130 - val_mae: 0.2130\n",
      "Epoch 391/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.2149 - val_mae: 0.2149\n",
      "Epoch 392/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.2083 - val_mae: 0.2083\n",
      "Epoch 393/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.1954 - val_mae: 0.1954\n",
      "Epoch 394/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.2065 - val_mae: 0.2065\n",
      "Epoch 395/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2037 - val_mae: 0.2037\n",
      "Epoch 396/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.1970 - val_mae: 0.1970\n",
      "Epoch 397/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0279 - mae: 0.0279 - val_loss: 0.1970 - val_mae: 0.1970\n",
      "Epoch 398/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.1961 - val_mae: 0.1961\n",
      "Epoch 399/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2116 - val_mae: 0.2116\n",
      "Epoch 400/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2068 - val_mae: 0.2068\n",
      "Epoch 401/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.1992 - val_mae: 0.1992\n",
      "Epoch 402/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.1884 - val_mae: 0.1884\n",
      "Epoch 403/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.1884 - val_mae: 0.1884\n",
      "Epoch 404/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.1968 - val_mae: 0.1968\n",
      "Epoch 405/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.2098 - val_mae: 0.2098\n",
      "Epoch 406/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2062 - val_mae: 0.2062\n",
      "Epoch 407/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.2155 - val_mae: 0.2155s: 0.0274 - ETA:\n",
      "Epoch 408/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2012 - val_mae: 0.2012\n",
      "Epoch 409/500\n",
      "769500/769500 [==============================] - 35s 46us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.1987 - val_mae: 0.1987: 0.0 - ETA: 2s - \n",
      "Epoch 410/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2027 - val_mae: 0.2027\n",
      "Epoch 411/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.2163 - val_mae: 0.2163\n",
      "Epoch 412/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.1986 - val_mae: 0.1986\n",
      "Epoch 413/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2101 - val_mae: 0.2101\n",
      "Epoch 414/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2045 - val_mae: 0.2045\n",
      "Epoch 415/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2000 - val_mae: 0.2000\n",
      "Epoch 416/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.1930 - val_mae: 0.1930\n",
      "Epoch 417/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.1943 - val_mae: 0.1943\n",
      "Epoch 418/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.1969 - val_mae: 0.1969\n",
      "Epoch 419/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2157 - val_mae: 0.2157\n",
      "Epoch 420/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2086 - val_mae: 0.2086\n",
      "Epoch 421/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.1978 - val_mae: 0.1978\n",
      "Epoch 422/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2033 - val_mae: 0.2033\n",
      "Epoch 423/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.1969 - val_mae: 0.1969\n",
      "Epoch 424/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.1954 - val_mae: 0.1954\n",
      "Epoch 425/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2079 - val_mae: 0.2079\n",
      "Epoch 426/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2086 - val_mae: 0.2086\n",
      "Epoch 427/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2162 - val_mae: 0.2162\n",
      "Epoch 428/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2046 - val_mae: 0.2046\n",
      "Epoch 429/500\n",
      "769500/769500 [==============================] - 34s 45us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2057 - val_mae: 0.2057\n",
      "Epoch 430/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.2095 - val_mae: 0.2095\n",
      "Epoch 431/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.2150 - val_mae: 0.2150\n",
      "Epoch 432/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.2042 - val_mae: 0.2042\n",
      "Epoch 433/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.2075 - val_mae: 0.2075\n",
      "Epoch 434/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.1989 - val_mae: 0.1989\n",
      "Epoch 435/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.1984 - val_mae: 0.1984\n",
      "Epoch 436/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.1926 - val_mae: 0.1926\n",
      "Epoch 437/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.1992 - val_mae: 0.1992\n",
      "Epoch 438/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2168 - val_mae: 0.2168\n",
      "Epoch 439/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.1952 - val_mae: 0.1952\n",
      "Epoch 440/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.2006 - val_mae: 0.2006\n",
      "Epoch 441/500\n",
      "769500/769500 [==============================] - 38s 49us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2023 - val_mae: 0.2023\n",
      "Epoch 442/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.1970 - val_mae: 0.1970\n",
      "Epoch 443/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2064 - val_mae: 0.2064\n",
      "Epoch 444/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.2090 - val_mae: 0.2090\n",
      "Epoch 445/500\n",
      "769500/769500 [==============================] - 38s 49us/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.2023 - val_mae: 0.2023\n",
      "Epoch 446/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.2065 - val_mae: 0.2065\n",
      "Epoch 447/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2042 - val_mae: 0.2042\n",
      "Epoch 448/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.1909 - val_mae: 0.1909\n",
      "Epoch 449/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0268 - mae: 0.0268 - val_loss: 0.1981 - val_mae: 0.1981\n",
      "Epoch 450/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1961 - val_mae: 0.1961\n",
      "Epoch 451/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.1922 - val_mae: 0.1922\n",
      "Epoch 452/500\n",
      "769500/769500 [==============================] - 38s 49us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2007 - val_mae: 0.2007\n",
      "Epoch 453/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.2071 - val_mae: 0.2071\n",
      "Epoch 454/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.2035 - val_mae: 0.2035\n",
      "Epoch 455/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2031 - val_mae: 0.2031\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 36s 47us/step - loss: 0.0265 - mae: 0.0265 - val_loss: 0.2024 - val_mae: 0.2024\n",
      "Epoch 457/500\n",
      "769500/769500 [==============================] - 36s 47us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.2067 - val_mae: 0.2067\n",
      "Epoch 458/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.2094 - val_mae: 0.2094\n",
      "Epoch 459/500\n",
      "769500/769500 [==============================] - 36s 47us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.1950 - val_mae: 0.1950\n",
      "Epoch 460/500\n",
      "769500/769500 [==============================] - 36s 47us/step - loss: 0.0265 - mae: 0.0265 - val_loss: 0.2158 - val_mae: 0.2158\n",
      "Epoch 461/500\n",
      "769500/769500 [==============================] - 36s 47us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2120 - val_mae: 0.2120\n",
      "Epoch 462/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2203 - val_mae: 0.2203\n",
      "Epoch 463/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.2010 - val_mae: 0.2010\n",
      "Epoch 464/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.1971 - val_mae: 0.1971\n",
      "Epoch 465/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.1913 - val_mae: 0.1913\n",
      "Epoch 466/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.2027 - val_mae: 0.2027\n",
      "Epoch 467/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.2021 - val_mae: 0.2021\n",
      "Epoch 468/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2080 - val_mae: 0.2080\n",
      "Epoch 469/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.2059 - val_mae: 0.2059\n",
      "Epoch 470/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.1973 - val_mae: 0.1973271 \n",
      "Epoch 471/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1951 - val_mae: 0.1951\n",
      "Epoch 472/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.2037 - val_mae: 0.2037\n",
      "Epoch 473/500\n",
      "769500/769500 [==============================] - 36s 47us/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.1989 - val_mae: 0.1989\n",
      "Epoch 474/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1987 - val_mae: 0.1987\n",
      "Epoch 475/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.2061 - val_mae: 0.2061\n",
      "Epoch 476/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1944 - val_mae: 0.1944\n",
      "Epoch 477/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1957 - val_mae: 0.1957\n",
      "Epoch 478/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0268 - mae: 0.0268 - val_loss: 0.1967 - val_mae: 0.1967\n",
      "Epoch 479/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.2009 - val_mae: 0.2009\n",
      "Epoch 480/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0265 - mae: 0.0265 - val_loss: 0.2126 - val_mae: 0.2126\n",
      "Epoch 481/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0268 - mae: 0.0268 - val_loss: 0.1977 - val_mae: 0.1977\n",
      "Epoch 482/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.2098 - val_mae: 0.2098\n",
      "Epoch 483/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.2055 - val_mae: 0.2055\n",
      "Epoch 484/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1965 - val_mae: 0.1965\n",
      "Epoch 485/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0264 - mae: 0.0264 - val_loss: 0.2014 - val_mae: 0.2014\n",
      "Epoch 486/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0264 - mae: 0.0264 - val_loss: 0.2137 - val_mae: 0.2137\n",
      "Epoch 487/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.2155 - val_mae: 0.2155\n",
      "Epoch 488/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.2018 - val_mae: 0.2018\n",
      "Epoch 489/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1881 - val_mae: 0.1881\n",
      "Epoch 490/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.1887 - val_mae: 0.1887\n",
      "Epoch 491/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.2066 - val_mae: 0.2066\n",
      "Epoch 492/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.1983 - val_mae: 0.1983\n",
      "Epoch 493/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.2046 - val_mae: 0.2046\n",
      "Epoch 494/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.1942 - val_mae: 0.1942\n",
      "Epoch 495/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.2107 - val_mae: 0.2107\n",
      "Epoch 496/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.2093 - val_mae: 0.2093\n",
      "Epoch 497/500\n",
      "769500/769500 [==============================] - 37s 49us/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.2008 - val_mae: 0.2008\n",
      "Epoch 498/500\n",
      "769500/769500 [==============================] - 37s 48us/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.2099 - val_mae: 0.2099\n",
      "Epoch 499/500\n",
      "769500/769500 [==============================] - 35s 45us/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.2059 - val_mae: 0.2059\n",
      "Epoch 500/500\n",
      "769500/769500 [==============================] - 34s 44us/step - loss: 0.0268 - mae: 0.0268 - val_loss: 0.1984 - val_mae: 0.1984\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  # model 초기화 \n",
    "model.add(Dense(units=452, activation='relu', input_dim=226))  # 첫번째 은닉층  # 226개 feature, 160개 뉴런, relu 함수를 활성화 함수로 사용\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=339, activation='relu'))   # 두번째 은닉층  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=226, activation='relu'))   # 세번째 은닉층  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=113, activation='relu'))   # 네번째 은닉층\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=4, activation='linear'))   # 출력층 (4개의 output을 도출해내야되기 때문에 units = 4)\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=300, batch_size=1000, validation_split = 0.05)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dd4381b5c8>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = scaler.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission 파일을 생성합니다.\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission = sample_sub+pred_test\n",
    "submission.to_csv('submission2_scaler_hidden_layer_add_500.csv')  # 2.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission 파일을 생성합니다.\n",
    "'''sample_sub = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission = sample_sub+pred_test\n",
    "submission.to_csv('submission2_scaler_hidden_layer_add_150.csv')  # 3.2169996'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch 수를 늘렸을 때 성능이 더 좋음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.4258 - mae: 0.4258 - val_loss: 0.5256 - val_mae: 0.5256\n",
      "Epoch 2/30\n",
      "769500/769500 [==============================] - 52s 68us/step - loss: 0.2752 - mae: 0.2752 - val_loss: 0.4489 - val_mae: 0.4489\n",
      "Epoch 3/30\n",
      "769500/769500 [==============================] - 57s 74us/step - loss: 0.2242 - mae: 0.2242 - val_loss: 0.4066 - val_mae: 0.4066\n",
      "Epoch 4/30\n",
      "769500/769500 [==============================] - 56s 73us/step - loss: 0.1943 - mae: 0.1943 - val_loss: 0.3782 - val_mae: 0.3782\n",
      "Epoch 5/30\n",
      "769500/769500 [==============================] - 56s 73us/step - loss: 0.1740 - mae: 0.1740 - val_loss: 0.3658 - val_mae: 0.3658\n",
      "Epoch 6/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.3450 - val_mae: 0.3450\n",
      "Epoch 7/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.1467 - mae: 0.1467 - val_loss: 0.3316 - val_mae: 0.3316\n",
      "Epoch 8/30\n",
      "769500/769500 [==============================] - 56s 73us/step - loss: 0.1376 - mae: 0.1376 - val_loss: 0.3203 - val_mae: 0.3203\n",
      "Epoch 9/30\n",
      "769500/769500 [==============================] - 58s 75us/step - loss: 0.1289 - mae: 0.1289 - val_loss: 0.3128 - val_mae: 0.3128\n",
      "Epoch 10/30\n",
      "769500/769500 [==============================] - 52s 68us/step - loss: 0.1226 - mae: 0.1226 - val_loss: 0.2984 - val_mae: 0.2984\n",
      "Epoch 11/30\n",
      "769500/769500 [==============================] - 53s 68us/step - loss: 0.1166 - mae: 0.1166 - val_loss: 0.2924 - val_mae: 0.2924\n",
      "Epoch 12/30\n",
      "769500/769500 [==============================] - 55s 72us/step - loss: 0.1112 - mae: 0.1112 - val_loss: 0.2958 - val_mae: 0.2958\n",
      "Epoch 13/30\n",
      "769500/769500 [==============================] - 54s 70us/step - loss: 0.1070 - mae: 0.1070 - val_loss: 0.2857 - val_mae: 0.2857\n",
      "Epoch 14/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.1029 - mae: 0.1029 - val_loss: 0.2756 - val_mae: 0.2756\n",
      "Epoch 15/30\n",
      "769500/769500 [==============================] - 55s 71us/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.2770 - val_mae: 0.2770\n",
      "Epoch 16/30\n",
      "769500/769500 [==============================] - 54s 71us/step - loss: 0.0961 - mae: 0.0961 - val_loss: 0.2811 - val_mae: 0.2811\n",
      "Epoch 17/30\n",
      "769500/769500 [==============================] - 51s 66us/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.2613 - val_mae: 0.2613\n",
      "Epoch 18/30\n",
      "769500/769500 [==============================] - 52s 68us/step - loss: 0.0907 - mae: 0.0907 - val_loss: 0.2655 - val_mae: 0.2655\n",
      "Epoch 19/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.0890 - mae: 0.0890 - val_loss: 0.2612 - val_mae: 0.2612\n",
      "Epoch 20/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.0867 - mae: 0.0867 - val_loss: 0.2653 - val_mae: 0.2653\n",
      "Epoch 21/30\n",
      "769500/769500 [==============================] - 51s 66us/step - loss: 0.0844 - mae: 0.0844 - val_loss: 0.2702 - val_mae: 0.2702\n",
      "Epoch 22/30\n",
      "769500/769500 [==============================] - 50s 65us/step - loss: 0.0828 - mae: 0.0828 - val_loss: 0.2660 - val_mae: 0.2660\n",
      "Epoch 23/30\n",
      "769500/769500 [==============================] - 55s 72us/step - loss: 0.0813 - mae: 0.0813 - val_loss: 0.2573 - val_mae: 0.2573\n",
      "Epoch 24/30\n",
      "769500/769500 [==============================] - 54s 70us/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.2522 - val_mae: 0.2522\n",
      "Epoch 25/30\n",
      "769500/769500 [==============================] - 52s 67us/step - loss: 0.0783 - mae: 0.0783 - val_loss: 0.2397 - val_mae: 0.2397\n",
      "Epoch 26/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.0770 - mae: 0.0770 - val_loss: 0.2569 - val_mae: 0.2569\n",
      "Epoch 27/30\n",
      "769500/769500 [==============================] - 56s 72us/step - loss: 0.0757 - mae: 0.0757 - val_loss: 0.2365 - val_mae: 0.2365\n",
      "Epoch 28/30\n",
      "769500/769500 [==============================] - 54s 70us/step - loss: 0.0746 - mae: 0.0746 - val_loss: 0.2505 - val_mae: 0.2505\n",
      "Epoch 29/30\n",
      "769500/769500 [==============================] - 52s 68us/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.2400 - val_mae: 0.2400\n",
      "Epoch 30/30\n",
      "769500/769500 [==============================] - 53s 69us/step - loss: 0.0725 - mae: 0.0725 - val_loss: 0.2556 - val_mae: 0.2556\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  # model 초기화 \n",
    "model.add(Dense(units=452, activation='relu', input_dim=226))  # 첫번째 은닉층  # 226개 feature, 160개 뉴런, relu 함수를 활성화 함수로 사용\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=339, activation='relu'))   # 두번째 은닉층  \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=226, activation='relu'))   # 세번째 은닉층  \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=113, activation='relu'))   # 네번째 은닉층\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=4, activation='linear'))   # 출력층 (4개의 output을 도출해내야되기 때문에 units = 4)\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=30, batch_size=1000, validation_split = 0.05)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2314d634b08>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = scaler.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission 파일을 생성합니다.\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission = sample_sub+pred_test\n",
    "submission.to_csv('submission2_scaler_batchnorm.csv')  # batchnorm 추가한 결과 5.56 \n",
    "# standard scaler 적용 후에는 batchnorm을 안했을 때 성능이 더 좋음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종적으로 scaler 적용, hidden layer를 추가하여 (4개의 층이 생성됨), epoch = 500으로 했을 때 점수가 2.67로 가장 좋았음.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-flod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.wrappers.scikit_learn import KerasRegressor \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "import numpy   # Function to create model, required for KerasClassifier \n",
    "\n",
    "def create_model(): # create model \n",
    "\n",
    "    model = Sequential()  # model 초기화 \n",
    "    model.add(Dense(units=452, activation='relu', input_dim=226))  # 첫번째 은닉층  # 226개 feature, 160개 뉴런, relu 함수를 활성화 함수로 사용\n",
    "    model.add(Dense(units=339, activation='relu'))   # 두번째 은닉층  \n",
    "    model.add(Dense(units=226, activation='relu'))   # 세번째 은닉층  \n",
    "    model.add(Dense(units=113, activation='relu'))   # 네번째 은닉층\n",
    "    model.add(Dense(units=4, activation='linear'))   # 출력층 (4개의 output을 도출해내야되기 때문에 units = 4)\n",
    "\n",
    "    # Compile model \n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['mae'])    \n",
    "    \n",
    "    return model   # fix random seed for reproducibility \n",
    "\n",
    "seed = 7 \n",
    "\n",
    "numpy.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model \n",
    "model = KerasRegressor(build_fn=create_model, epochs=150, batch_size=1000, verbose=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook(results = cross_val_score(model, train_x, train_y, cv=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test  = estimator.predict(test_x)\n",
    "pred_test = scaler.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission 파일을 생성합니다.\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission = sample_sub+pred_test\n",
    "submission.to_csv('submission_kfold.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-fold는 너무 오래 걸려 시간 관계상 하지 못하여 다음 주에 돌린 후 결과 공유해보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
