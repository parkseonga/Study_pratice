{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import missingno as msno\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import kurtosis, iqr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from detecta import detect_peaks\n",
    "from changepy import pelt\n",
    "from changepy.costs import normal_mean, normal_var, normal_meanvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['layer_1', 'layer_2', 'layer_3', 'layer_4', '0', '1', '2', '3', '4',\n",
      "       '5',\n",
      "       ...\n",
      "       '216', '217', '218', '219', '220', '221', '222', '223', '224', '225'],\n",
      "      dtype='object', length=230)\n",
      "Index(['id', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
      "       ...\n",
      "       '216', '217', '218', '219', '220', '221', '222', '223', '224', '225'],\n",
      "      dtype='object', length=227)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#독립변수와 종속변수를 분리합니다.\n",
    "train_X = train.iloc[:,4:]\n",
    "train_Y = train.iloc[:,0:4]\n",
    "test_X = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms, rss 정의\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "def rss(x):\n",
    "    return rms(x)*len(x)\n",
    "\n",
    "def skewness(x):\n",
    "    return (sum((x-np.mean(x))**3)/len(x))/(sum((x-np.mean(x))**2)/len(x))**(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import kurtosis, iqr\n",
    "\n",
    "function_list = ['mean', 'min', 'max', 'std', skewness, rss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>skewness</th>\n",
       "      <th>rss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.211725</td>\n",
       "      <td>0.060860</td>\n",
       "      <td>0.653231</td>\n",
       "      <td>0.144346</td>\n",
       "      <td>1.391504</td>\n",
       "      <td>57.871515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259477</td>\n",
       "      <td>0.034894</td>\n",
       "      <td>0.750391</td>\n",
       "      <td>0.217637</td>\n",
       "      <td>0.805334</td>\n",
       "      <td>76.468513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.310657</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>0.805305</td>\n",
       "      <td>0.260747</td>\n",
       "      <td>0.472784</td>\n",
       "      <td>91.577755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.361292</td>\n",
       "      <td>0.030385</td>\n",
       "      <td>0.819105</td>\n",
       "      <td>0.278850</td>\n",
       "      <td>0.199020</td>\n",
       "      <td>103.058280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.403067</td>\n",
       "      <td>0.027361</td>\n",
       "      <td>0.790030</td>\n",
       "      <td>0.276715</td>\n",
       "      <td>-0.061827</td>\n",
       "      <td>110.415481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.431630</td>\n",
       "      <td>0.027519</td>\n",
       "      <td>0.734198</td>\n",
       "      <td>0.258159</td>\n",
       "      <td>-0.328845</td>\n",
       "      <td>113.598502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.433948</td>\n",
       "      <td>0.030484</td>\n",
       "      <td>0.695156</td>\n",
       "      <td>0.219381</td>\n",
       "      <td>-0.593736</td>\n",
       "      <td>109.842879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.411927</td>\n",
       "      <td>0.033531</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.180273</td>\n",
       "      <td>-0.535266</td>\n",
       "      <td>101.584003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.379020</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.617094</td>\n",
       "      <td>0.160536</td>\n",
       "      <td>-0.205367</td>\n",
       "      <td>92.994025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean       min       max       std  skewness         rss\n",
       "1  0.211725  0.060860  0.653231  0.144346  1.391504   57.871515\n",
       "2  0.259477  0.034894  0.750391  0.217637  0.805334   76.468513\n",
       "3  0.310657  0.027712  0.805305  0.260747  0.472784   91.577755\n",
       "4  0.361292  0.030385  0.819105  0.278850  0.199020  103.058280\n",
       "5  0.403067  0.027361  0.790030  0.276715 -0.061827  110.415481\n",
       "6  0.431630  0.027519  0.734198  0.258159 -0.328845  113.598502\n",
       "7  0.433948  0.030484  0.695156  0.219381 -0.593736  109.842879\n",
       "8  0.411927  0.033531  0.677778  0.180273 -0.535266  101.584003\n",
       "9  0.379020  0.059130  0.617094  0.160536 -0.205367   92.994025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.iloc[1:10,:].aggregate(function_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary = train_X.aggregate(function_list,axis=1)\n",
    "test_summary = test_X.aggregate(function_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = list(train_X)\n",
    "feature_cols[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from changepy import pelt\n",
    "from changepy.costs import normal_mean, normal_var, normal_meanvar\n",
    "\n",
    "train_peak = []\n",
    "\n",
    "for i in range(len(train_X)):\n",
    "    cp1 = len(pelt(normal_mean(train_X.iloc[i,][feature_cols], np.var(train_X.iloc[i,][feature_cols])), len(train_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp2 = len(pelt(normal_mean(train_X.iloc[i,][feature_cols], np.var(train_X.iloc[i,][feature_cols])), len(train_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp3 = len(pelt(normal_var(train_X.iloc[i,][feature_cols], np.mean(train_X.iloc[i,][feature_cols])), len(train_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp4 = len(pelt(normal_var(train_X.iloc[i,][feature_cols], np.mean(train_X.iloc[i,][feature_cols])), len(train_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp5 = len(pelt(normal_meanvar(train_X.iloc[i,][feature_cols]), len(train_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp6 = len(pelt(normal_meanvar(train_X.iloc[i,][feature_cols]), len(train_X.iloc[i,][feature_cols]))) - 1\n",
    "    train_peak.append(pd.DataFrame({'d':[i], 'cp1':[cp1], 'cp2':[cp2], 'cp3':[cp3], 'cp4':[cp4], 'cp5':[cp5], 'cp6':[cp6]}))\n",
    "\n",
    "train_peak = pd.concat(train_peak)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_peak = []\n",
    "\n",
    "for i in range(len(test_X)):\n",
    "    cp1 = len(pelt(normal_mean(test_X.iloc[i,][feature_cols], np.var(test_X.iloc[i,][feature_cols])), len(test_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp2 = len(pelt(normal_mean(test_X.iloc[i,][feature_cols], np.var(test_X.iloc[i,][feature_cols])), len(test_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp3 = len(pelt(normal_var(test_X.iloc[i,][feature_cols], np.mean(test_X.iloc[i,][feature_cols])), len(test_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp4 = len(pelt(normal_var(test_X.iloc[i,][feature_cols], np.mean(test_X.iloc[i,][feature_cols])), len(test_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp5 = len(pelt(normal_meanvar(test_X.iloc[i,][feature_cols]), len(test_X.iloc[i,][feature_cols]))) - 1\n",
    "    cp6 = len(pelt(normal_meanvar(test_X.iloc[i,][feature_cols]), len(test_X.iloc[i,][feature_cols]))) - 1\n",
    "    test_peak.append(pd.DataFrame({'d':[i], 'cp1':[cp1], 'cp2':[cp2], 'cp3':[cp3], 'cp4':[cp4], 'cp5':[cp5], 'cp6':[cp6]}))\n",
    "\n",
    "test_peak = pd.concat(test_peak)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_peak_rslt = pd.DataFrame()\n",
    "\n",
    "for i in range(len(train_X)):\n",
    "    p = detect_peaks(train_X.iloc[i,][feature_cols], mph=4)\n",
    "    f_n = len(p)\n",
    "    p_interval = np.mean(np.diff(p)) if f_n > 2 else 0\n",
    "    p_interval_std = np.std(np.diff(p)) if f_n > 2 else 0\n",
    "    p_mean = np.mean(train_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    p_max = np.max(train_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    p_min = np.min(train_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    p_std = np.std(train_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    row_peak = pd.DataFrame({'d': i,\n",
    "                             'f_n':[f_n],\n",
    "                             'p_interval':[p_interval],\n",
    "                             'p_interval_std':[p_interval_std],\n",
    "                             'p_mean':[p_mean],\n",
    "                             'p_max':[p_max],\n",
    "                             'p_min':[p_min],\n",
    "                             'p_std':[p_std]})\n",
    "    train_peak_rslt = pd.concat([train_peak_rslt, row_peak])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_peak_rslt = pd.DataFrame()\n",
    "\n",
    "for i in range(len(test_X)):\n",
    "    p = detect_peaks(test_X.iloc[i,][feature_cols], mph=4)\n",
    "    f_n = len(p)\n",
    "    p_interval = np.mean(np.diff(p)) if f_n > 2 else 0\n",
    "    p_interval_std = np.std(np.diff(p)) if f_n > 2 else 0\n",
    "    p_mean = np.mean(test_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    p_max = np.max(test_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    p_min = np.min(test_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    p_std = np.std(test_X.iloc[i,][feature_cols][p]) if f_n > 0 else 0\n",
    "    row_peak = pd.DataFrame({'d': i,\n",
    "                         'f_n':[f_n],\n",
    "                         'p_interval':[p_interval],\n",
    "                         'p_interval_std':[p_interval_std],\n",
    "                         'p_mean':[p_mean],\n",
    "                         'p_max':[p_max],\n",
    "                         'p_min':[p_min],\n",
    "                         'p_std':[p_std]})\n",
    "    test_peak_rslt = pd.concat([test_peak_rslt, row_peak])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crest factor 추출\n",
    "\n",
    "def crest(x):\n",
    "    return np.max(x)/rms(x)\n",
    "\n",
    "crests_train = pd.DataFrame()\n",
    "\n",
    "for i in range(len(train_X)):\n",
    "    cfR = crest(train_X.iloc[i,][feature_cols])\n",
    "    cfA = crest(train_X.iloc[i,][feature_cols])\n",
    "    row_crest = pd.DataFrame({'d': i, 'cfR': [cfR], 'cfA': [cfA]})\n",
    "    crests_train = pd.concat([crests_train, row_crest])\n",
    "\n",
    "crests_test = pd.DataFrame()\n",
    "\n",
    "for i in range(len(test_X)):\n",
    "    cfR = crest(test_X.iloc[i,][feature_cols])\n",
    "    cfA = crest(test_X.iloc[i,][feature_cols])\n",
    "    row_crest = pd.DataFrame({'d': i, 'cfR': [cfR], 'cfA': [cfA]})\n",
    "    crests_test = pd.concat([crests_test, row_crest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_peak.to_pickle('train_peak.pkl')\n",
    "test_peak.to_pickle('test_peak.pkl')\n",
    "train_peak_rslt.to_pickle('train_peak_rslt.pkl')\n",
    "test_peak_rslt.to_pickle('test_peak_rslt.pkl')\n",
    "crests_train.to_pickle('crests_train.pkl')\n",
    "crests_test.to_pickle('crests_test.pkl')\n",
    "train_summary.to_pickle('train_summary.pkl')\n",
    "test_summary.to_pickle('test_summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-84d59823ce98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtemp_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtemp_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpeak_final_train2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeak_final_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-84d59823ce98>\u001b[0m in \u001b[0;36mid_f\u001b[1;34m(d)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mid_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mnumbers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\d+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'exp_no'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'activity'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# peak_final\n",
    "peak_final_train = pd.merge(train_peak_rslt, crests_train, on='d')\n",
    "peak_final_train = pd.merge(peak_final_train, train_peak, on='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_final\n",
    "peak_final_test = pd.merge(test_peak_rslt, crests_test, on='d')\n",
    "peak_final_test = pd.merge(peak_final_test, test_peak, on='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def id_f(d):\n",
    "    numbers = re.findall('\\d+', d)\n",
    "    return pd.DataFrame({'exp_no': [numbers[0]], 'id':[numbers[1]], 'activity': [d.split('_')[0]]})\n",
    "\n",
    "# train적용\n",
    "temp_train = pd.DataFrame()\n",
    "\n",
    "for i in range(len(train_X)):\n",
    "    temp_train = pd.concat([temp_train, id_f(i)])\n",
    "\n",
    "peak_final_train2 = pd.concat([peak_final_train, temp_train.reset_index()], axis=1)\n",
    "\n",
    "           \n",
    "# test 적용 \n",
    "peak_final_test = pd.merge(test_peak_rslt, crests_train, on='d')\n",
    "peak_final_test = pd.merge(peak_final_test, train_peak, on='d')             \n",
    "               \n",
    "temp_test = pd.DataFrame()\n",
    "               \n",
    "for i in range(len(test_X)):\n",
    "    temp_test = pd.concat([temp_test, id_f(i)])\n",
    "\n",
    "peak_final_test2 = pd.concat([peak_final_test, temp_test.reset_index()], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_final_test2.to_pickle('final+data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통계량 + peak으로 예측\n",
    "\n",
    "peak_final3 = pd.concat([peak_final2, HAR_train_ext], axis=1)\n",
    "\n",
    "activity_all = peak_final3.drop(['d', 'index', 'exp_no', 'id', 'activity'], axis=1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=123456)\n",
    "accuracy = cross_val_score(rf, activity_all, peak_final3['activity'], cv=10)\n",
    "precision = cross_val_score(rf, activity_all, peak_final3['activity'], cv=10, scoring='precision_macro')\n",
    "recall = cross_val_score(rf, activity_all, peak_final3['activity'], cv=10, scoring='recall_macro')\n",
    "score = {'accuracy': np.mean(accuracy),\n",
    "         'recall': np.mean(recall),\n",
    "         'precision': np.mean(precision)}\n",
    "print(json.dumps(score, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
